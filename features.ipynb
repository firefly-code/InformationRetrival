{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,  ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi  # lightweight BM25 implementation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = ir_datasets.load(\"trec-robust04\")",
   "id": "e5fb06a1dfd7d9d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Features",
   "id": "c7c527b981c671eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Overlap between query and title/body",
   "id": "70cc6d6e3c28088f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#count how many unique query terms appear in the title\n",
    "def keyword_overlap_title_unique(query, doc):\n",
    "    query_terms = set(re.findall(r'\\w+', query.title.lower()))\n",
    "    doc_terms = set(re.findall(r'\\w+', doc.title.lower())) if doc.title else set()\n",
    "    return len(query_terms.intersection(doc_terms))\n",
    "\n",
    "#count how many query terms appear in the title in total\n",
    "def keyword_overlap_title_total(query, doc):\n",
    "    query_terms = re.findall(r'\\w+', query.title.lower())\n",
    "    doc_terms = re.findall(r'\\w+', doc.title.lower()) if doc.title else []\n",
    "\n",
    "    count = 0\n",
    "    for term in query_terms:\n",
    "        count += doc_terms.count(term)\n",
    "    return count"
   ],
   "id": "d8a7c53a24694d57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#count how many unique query terms appear in the body\n",
    "def keyword_overlap_body_unique(query, doc):\n",
    "    query_terms = set(re.findall(r'\\w+', query.title.lower()))\n",
    "    doc_terms = set(re.findall(r'\\w+', doc.text.lower()))\n",
    "    return len(query_terms.intersection(doc_terms))\n",
    "\n",
    "#count how many query terms appear in the body in total\n",
    "def keyword_overlap_body_total(query, doc):\n",
    "    query_terms = re.findall(r'\\w+', query.title.lower())\n",
    "    doc_terms = re.findall(r'\\w+', doc.text.lower())\n",
    "\n",
    "    count = 0\n",
    "    for term in query_terms:\n",
    "        count += doc_terms.count(term)\n",
    "    return count"
   ],
   "id": "641eecafa339d9d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def keyword_overlap_title_stopwords(query, doc):\n",
    "    query_terms = set(re.findall(r'\\w+', query.title.lower()))\n",
    "    doc_terms = set(re.findall(r'\\w+', doc.title.lower()))\n",
    "\n",
    "    # Remove stopwords\n",
    "    query_terms -= set(ENGLISH_STOP_WORDS)\n",
    "    doc_terms -= set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "    return len(query_terms.intersection(doc_terms))\n",
    "\n",
    "def keyword_overlap_body_stopwords(query, doc):\n",
    "    query_terms = set(re.findall(r'\\w+', query.title.lower()))\n",
    "    doc_terms = set(re.findall(r'\\w+', doc.text.lower()))\n",
    "\n",
    "    # Remove stopwords\n",
    "    query_terms -= set(ENGLISH_STOP_WORDS)\n",
    "    doc_terms -= set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "    return len(query_terms.intersection(doc_terms))"
   ],
   "id": "5291e0a8410dfb93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Absolute lengths",
   "id": "41e31d028dc61174"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def query_length(query):\n",
    "    tokens = re.findall(r'\\w+', query.title)\n",
    "    return len(tokens)\n",
    "\n",
    "def document_length(doc):\n",
    "    tokens = re.findall(r'\\w+', doc.text)\n",
    "    return len(tokens)"
   ],
   "id": "b6bb70c99b4497d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cosine similarity",
   "id": "f0861b4bdf0e2c00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def tfidf_cosine_similarity_body(query, doc, vectorizer):\n",
    "    query_vec = vectorizer.transform([query.title])\n",
    "    doc_vec = vectorizer.transform([doc.text])\n",
    "\n",
    "    cos_sim = cosine_similarity(query_vec, doc_vec)[0][0]\n",
    "    return float(cos_sim)"
   ],
   "id": "42904a041bbc61a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "bm25 score",
   "id": "1d243d71eead8726"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def bm25_score(query, bm25_model):\n",
    "    query_tokens = re.findall(r'\\w+', query.title.lower())\n",
    "\n",
    "    scores = bm25_model.get_scores(query_tokens)\n",
    "    return scores #bm25 values for query for all documents (in order of tokenized corpus)"
   ],
   "id": "f4b104cb4d730485"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Using the features  (example for query 1)",
   "id": "ecf7c6575a5ff755"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Formatting the FBIS dataset:",
   "id": "6aea7a17c604a551"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_path = \"data/FBIS\" #put correct path here\n",
    "\n",
    "raw_contents = []\n",
    "for fname in sorted(os.listdir(base_path)):\n",
    "    if fname.endswith(\".gz\"):\n",
    "        with gzip.open(os.path.join(base_path, fname), 'rt', encoding='latin-1') as f:\n",
    "            content = f.read()\n",
    "        docs = re.findall(r\"<DOC>.*?</DOC>\", content, re.DOTALL)\n",
    "        raw_contents.extend(docs)\n",
    "\n",
    "print(f\"Amount of documents: {len(raw_contents)}\\n\")"
   ],
   "id": "78feabde0601fc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    id: str\n",
    "    title: str\n",
    "    text: str\n",
    "    date: str\n",
    "    raw: str"
   ],
   "id": "6ca0321e53c54cbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "structured_docs = []\n",
    "\n",
    "for raw_doc in raw_contents:\n",
    "    docno_match = re.search(r\"<DOCNO>(.*?)</DOCNO>\", raw_doc)\n",
    "    docno = docno_match.group(1).strip() if docno_match else None\n",
    "\n",
    "    title_match = re.search(r\"<TI>(.*?)</TI>\", raw_doc, re.DOTALL | re.IGNORECASE)\n",
    "    title = title_match.group(1).strip() if title_match else None\n",
    "\n",
    "    text_blocks = re.findall(r\"<TEXT>(.*?)</TEXT>\", raw_doc, re.DOTALL | re.IGNORECASE)\n",
    "    text = \"\\n\".join(t.strip() for t in text_blocks) if text_blocks else None\n",
    "\n",
    "    date = re.search(r\"<DATE1>(.*?)</DATE1>\", raw_doc, re.DOTALL)\n",
    "    date = date.group(1).strip() if date else None\n",
    "\n",
    "    doc = Document(id=docno, raw=raw_doc, title=title, text=text, date=date)\n",
    "    structured_docs.append(doc)\n",
    "\n",
    "n=0\n",
    "print(structured_docs[n].id)\n",
    "print(structured_docs[n].title)\n",
    "print(structured_docs[n].date)\n",
    "print(structured_docs[n].text)"
   ],
   "id": "76de98c04e5423dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example query and docs",
   "id": "1b9edb1de739cc5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query1 = next(dataset.queries_iter())\n",
    "print(query1.query_id)\n",
    "print(query1.title)\n",
    "print(query1.description)\n",
    "len_query1 = len(query1.title.split())\n",
    "\n",
    "doc1 = structured_docs[0]\n",
    "doc2 = structured_docs[1]\n",
    "doc3 = structured_docs[2]\n",
    "\n",
    "test_docs = [doc1, doc2, doc3]"
   ],
   "id": "125445aa0065f9df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Overlapping words",
   "id": "eef9adf61de9803f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for doc in structured_docs:\n",
    "    amount = keyword_overlap_title_unique(query1, doc)\n",
    "    if amount >= len_query1-1:\n",
    "        print(doc.title)\n"
   ],
   "id": "cc7476b4ebd1ce36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for doc in structured_docs:\n",
    "    num = keyword_overlap_body_unique(query1, doc)\n",
    "    if num == len_query1:\n",
    "        print(f\"#{num} - {doc.title}\")\n"
   ],
   "id": "3eac3cda348f6824"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#print a document with more than 100 overlapping terms\n",
    "amount = 100\n",
    "for doc in structured_docs:\n",
    "    num = keyword_overlap_body_total(query1, doc, amount)\n",
    "    if num > amount:\n",
    "        print(\"Doc ID: \", doc.id)\n",
    "        print(\"Title: \", doc.title)\n",
    "        print(\"Amount: \", num)\n",
    "        print(\"Text: \\n\", doc.text)\n",
    "        break # only print the first one with more than 100"
   ],
   "id": "95fec22828982418"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "absolute lengths",
   "id": "82c4db13bb19b191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(query_length(query1))\n",
    "\n",
    "for doc in test_docs:\n",
    "    print(document_length(doc))"
   ],
   "id": "ff5dcf7fbc112d87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "cosine similarity",
   "id": "18fc5ca9a48133a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorizer.fit([doc.text for doc in structured_docs])"
   ],
   "id": "78c224524524524b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#print all with a cosine similarity > 0.4\n",
    "for idx, doc in enumerate(structured_docs):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    cos = tfidf_cosine_similarity_body(query1, doc, vectorizer)\n",
    "    if cos > 0.4:\n",
    "        print(f\"cos: {cos}\")\n",
    "        print(f\"doc id: {doc.id}\")\n",
    "        print(f\"doc title: {doc.title}\")\n",
    "        print(\"-\"*40)"
   ],
   "id": "acbc435b34877bc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "BM-25 score",
   "id": "75145896b3aeb799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_docs = structured_docs\n",
    "all_text = [doc.text for doc in all_docs]\n",
    "\n",
    "tokenized_corpus = [re.findall(r'\\w+', text.lower()) for text in all_text]"
   ],
   "id": "e6720a049396bde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bm25_model = BM25Okapi(tokenized_corpus)",
   "id": "a7cceb1f55d6af76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scored_documents = []\n",
    "all_bm25_scores = bm25_score(query1, bm25_model)"
   ],
   "id": "fc7653ea21de595f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#showing the top 5 most similar ones accoring to bm25:\n",
    "for i, score in enumerate(all_bm25_scores):\n",
    "    doc_object = structured_docs[i]\n",
    "    scored_documents.append({'doc': doc_object, 'bm25 score': score})\n",
    "\n",
    "ranked_results = sorted(scored_documents, key=lambda x: x['bm25 score'], reverse=True)\n",
    "\n",
    "for i in range(5):\n",
    "    print(ranked_results[i]['bm25 score'])\n",
    "    print(ranked_results[i]['doc'].id)\n",
    "    print(ranked_results[i]['doc'].title)\n",
    "    print(ranked_results[i]['doc'].text)"
   ],
   "id": "6a74a365b0979ee0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
